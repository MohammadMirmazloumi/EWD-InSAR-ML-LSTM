{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf10a6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, mean_absolute_error\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaa98e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepath for the dataset\n",
    "FILE_PATH = \"data/BCN-HRB_Points.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca0b079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "SKIPPED_COL = 10  # Columns before starting the time series data\n",
    "ANOMALY_PERIOD = 10  # The period used to detect anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836f09eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "\n",
    "def load_data(filepath):\n",
    "    \"\"\"Load dataset from file.\"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        raise FileNotFoundError(f\"File {filepath} not found.\")\n",
    "    \n",
    "    data = np.loadtxt(filepath, skiprows=1)\n",
    "    return data\n",
    "\n",
    "def preprocess_data(data):\n",
    "    \"\"\"Preprocess the dataset by splitting into time series, train/test sets.\"\"\"\n",
    "    ts_data = data[:, SKIPPED_COL:]  # Time series of all points\n",
    "    len_ts = data.shape[1]\n",
    "    \n",
    "    input_model = data[:, len_ts-70:]  # Last one year values of time series\n",
    "    input_train_test = data[:, len_ts-131:len_ts-70]\n",
    "\n",
    "    x = input_train_test[:, :-1]\n",
    "    y = input_train_test[:, -1:]\n",
    "\n",
    "    return x, y, input_model, ts_data\n",
    "\n",
    "def split_data(x, y, test_size=0.3):\n",
    "    \"\"\"Split data into training and testing sets.\"\"\"\n",
    "    return train_test_split(x, y, test_size=test_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aef0682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to evaluate adjacent TS\n",
    "\n",
    "def residual_std(time_series):\n",
    "    \"\"\"Calculate the residual standard deviation.\"\"\"\n",
    "    x = np.arange(0, len(time_series) * 6, 6)\n",
    "    y = np.polyfit(x, time_series, 3, full=True)\n",
    "    rstd = np.sqrt(y[1] / (len(time_series) - 2))\n",
    "    return rstd\n",
    "\n",
    "def neighbor_ps(input_info, input_ts, n_row, n_col):\n",
    "    \"\"\"\n",
    "    Find the time series of neighboring points based on row and column.\n",
    "    \"\"\"\n",
    "    ts_n = np.empty((0, input_ts.shape[1]), float)\n",
    "\n",
    "    for i in range(-2, 3):\n",
    "        for j in range(-7, 8):\n",
    "            c = np.array([n_row + i, n_col + j])\n",
    "            id_n = np.argwhere(np.all(input_info[:, 1:3] == c, axis=1))\n",
    "            \n",
    "            if len(id_n) > 0 and not np.array_equal(c, [n_row, n_col]):\n",
    "                psts = input_ts[id_n, :].reshape(id_n.shape[0], -1)\n",
    "                ts_n = np.vstack((ts_n, psts[0, :]))\n",
    "                \n",
    "    return ts_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5687e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning model\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    \"\"\"Train XGBoost model.\"\"\"\n",
    "    regressor = MultiOutputRegressor(xgb.XGBRegressor())\n",
    "    return regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb2e733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to run anomaly detection and prediction.\"\"\"\n",
    "    # Load and preprocess data\n",
    "    data = load_data(FILE_PATH)\n",
    "    x, y, input_model, ts_data = preprocess_data(data)\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = split_data(x, y)\n",
    "    print(f\"Train/Test shapes: {X_train.shape}, {X_test.shape}, {y_train.shape}, {y_test.shape}\")\n",
    "\n",
    "    # Train model\n",
    "    model_xgb = train_model(X_train, y_train)\n",
    "\n",
    "    # Variables to store results\n",
    "    alerts_full = np.empty((0, ANOMALY_PERIOD - 1), float)\n",
    "    alerts = []\n",
    "\n",
    "    # Process each time series point for anomaly detection\n",
    "    for j in range(data.shape[0]):\n",
    "        X_0 = input_model[j:j + 1, :-ANOMALY_PERIOD]\n",
    "        XP = input_model[j, -ANOMALY_PERIOD:]\n",
    "        n_row, n_col = data[j, 1], data[j, 2]\n",
    "        x_n = neighbor_ps(data, input_model, n_row, n_col)\n",
    "        thr = 1.96 * residual_std(ts_data[j, :-ANOMALY_PERIOD])\n",
    "\n",
    "        A = []  # Store alert values\n",
    "        for i in range(0, len(XP) - 1):\n",
    "            P = model_xgb.predict(X_0)\n",
    "            n_p = np.mean(x_n[:, input_model.shape[1] - ANOMALY_PERIOD + i]) if len(x_n) > 0 else XP[i + 1]\n",
    "\n",
    "            # Detect anomalies based on thresholds\n",
    "            if abs(P - XP[i]) <= thr:\n",
    "                A.append(0)\n",
    "            elif abs(P - XP[i]) > thr and abs(P - n_p) <= thr:\n",
    "                A.append(0)\n",
    "            elif (P < XP[i] - thr and P > n_p + thr) or (P > XP[i] + thr and P < n_p - thr):\n",
    "                A.append(0)\n",
    "            elif (P < XP[i] - thr and P < n_p - thr) or (P > XP[i] + thr and P > n_p + thr):\n",
    "                A.append(2)\n",
    "\n",
    "        alerts_full = np.vstack((alerts_full, A))\n",
    "        alerts.append(sum(A))\n",
    "\n",
    "    # Save results\n",
    "    np.savetxt('results/alerts.csv', np.array(alerts).reshape(-1, 1), delimiter=',')\n",
    "    np.savetxt('results/alerts_full.csv', alerts_full, delimiter=',')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
